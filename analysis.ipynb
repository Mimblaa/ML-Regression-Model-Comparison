{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "individual_household_electric_power_consumption = fetch_ucirepo(id=235) \n",
    "\n",
    "X_original = individual_household_electric_power_consumption.data.features\n",
    "\n",
    "print(individual_household_electric_power_consumption.metadata)\n",
    "print(individual_household_electric_power_consumption.variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - sporządzić analizę statystyczną zbioru\n",
    "# policzyć korelację Pearsona i rangową Spearmana zmiennej objaśnianej ze zmiennymi objaśniającymi (cechami)\n",
    "# wyznaczyć macierz kowariancji między cechami\n",
    "\n",
    "X_original = individual_household_electric_power_consumption.data.features\n",
    "\n",
    "X = X_original[['Date', 'Time', 'Global_active_power', 'Global_reactive_power', \n",
    "                'Voltage', 'Global_intensity', 'Sub_metering_1', \n",
    "                'Sub_metering_2', 'Sub_metering_3']].copy()\n",
    "\n",
    "print(\"Basic information about the data:\")\n",
    "print(X.info())\n",
    "print(\"\\nFirst rows of data:\")\n",
    "print(X.head())\n",
    "\n",
    "X['datetime'] = pd.to_datetime(X['Date'] + ' ' + X['Time'], format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
    "X = X.drop(columns=['Date', 'Time'])\n",
    "\n",
    "numeric_columns = [\n",
    "    'Global_active_power', 'Global_reactive_power', 'Voltage', \n",
    "    'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3'\n",
    "]\n",
    "for col in numeric_columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(X.describe())\n",
    "\n",
    "missing_values = X.isnull().sum()\n",
    "print(\"\\nNumber of missing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "\n",
    "corr_matrix = X[numeric_columns].corr()\n",
    "print(\"\\nCorelation matrix:\")\n",
    "print(corr_matrix)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Corelation matrix')\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=(len(numeric_columns) + 1) // 2, ncols=2, figsize=(15, 5 * ((len(numeric_columns) + 1) // 2)))\n",
    "axes = axes.flatten()\n",
    "for ax, col in zip(axes, numeric_columns):\n",
    "    sns.histplot(X[col].dropna(), bins=50, kde=True, color='blue', ax=ax)\n",
    "    ax.set_title(f'Distribution of variable: {col}')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Frequency')\n",
    "for i in range(len(numeric_columns), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['Global_intensity']\n",
    "\n",
    "X = X.dropna()\n",
    "y = y[X.index]\n",
    "\n",
    "pearson_corr = X[numeric_columns].apply(lambda col: col.corr(y, method='pearson'))\n",
    "spearman_corr = X[numeric_columns].apply(lambda col: col.corr(y, method='spearman'))\n",
    "\n",
    "print(\"\\nPearson correlation between 'Global_intensity' and features:\")\n",
    "print(pearson_corr)\n",
    "\n",
    "print(\"\\nSpearman correlation between 'Global_intensity' and features:\")\n",
    "print(spearman_corr)\n",
    "\n",
    "corr_df = pd.DataFrame({\n",
    "    'Feature': numeric_columns,\n",
    "    'Pearson': pearson_corr.values,\n",
    "    'Spearman': spearman_corr.values\n",
    "})\n",
    "\n",
    "corr_df = corr_df.melt(id_vars='Feature', var_name='Correlation Type', value_name='Correlation')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=corr_df, x='Feature', y='Correlation', hue='Correlation Type')\n",
    "plt.title('Pearson and Spearman Correlation with \"Global_intensity\"')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "cov_matrix = X[numeric_columns].cov()\n",
    "print(\"\\nCovariance matrix between features:\")\n",
    "print(cov_matrix)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cov_matrix, annot=True, fmt='.2f', cmap='viridis')\n",
    "plt.title('Covariance matrix between features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus on 'Date' and 'Global_intensity' features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_original[['Date', 'Time', 'Global_intensity']].copy()\n",
    "\n",
    "# Combine 'Date' and 'Time' into a single 'Datetime' column \n",
    "# could be deleted if done in analysis\n",
    "X['Datetime'] = pd.to_datetime(X['Date'] + ' ' + X['Time'], format='%d/%m/%Y %H:%M:%S')\n",
    "# Convert 'Datetime' to Unix timestamp (seconds since 1970-01-01)\n",
    "X['Datetime'] = X['Datetime'].astype(np.int64) // 10**9  # Convert to seconds\n",
    "\n",
    "# Drop the original 'Date' and 'Time' columns as they are now redundant\n",
    "X.drop(columns=['Date', 'Time'], inplace=True)\n",
    "\n",
    "# Convert 'Global_intensity' to numeric, replacing any non-numeric values with meanof the coulmn \n",
    "# there is '?' sign in data \n",
    "X['Global_intensity'] = pd.to_numeric(X['Global_intensity'], errors='coerce')\n",
    "X['Global_intensity'].fillna(X['Global_intensity'].mean(), inplace=True)\n",
    "\n",
    "# Now 'X' has a single feature 'Datetime' in Unix timestamp format, and 'y' is the target variable\n",
    "y = X['Global_intensity'].copy()  # The dependent variable (Global_intensity)\n",
    "X.drop(columns=['Global_intensity'], inplace=True)  # Remove the target variable from features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X[['Datetime']])  # Standardize the single feature 'Datetime'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression()\n",
    "\n",
    "linear.fit(X_train, y_train)\n",
    "y_pred_linear = linear.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "ridge_params = {'alpha': [0.1, 1, 10, 100]}\n",
    "ridge_cv = GridSearchCV(ridge, ridge_params, cv=5, scoring='r2')\n",
    "\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_cv.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters for Ridge Regression:\", ridge_cv.best_params_)\n",
    "\n",
    "print(\"\\nResults for each alpha:\")\n",
    "for mean_score, params in zip(ridge_cv.cv_results_['mean_test_score'], ridge_cv.cv_results_['params']):\n",
    "    print(f\"Alpha: {params['alpha']} | Mean R²: {mean_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1, 10]}\n",
    "lasso_cv = GridSearchCV(lasso, lasso_params, cv=5, scoring='r2')\n",
    "\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_cv.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters for Lasso Regression:\", lasso_cv.best_params_)\n",
    "\n",
    "print(\"\\nResults for each alpha:\")\n",
    "for mean_score, params in zip(lasso_cv.cv_results_['mean_test_score'], lasso_cv.cv_results_['params']):\n",
    "    print(f\"Alpha: {params['alpha']} | Mean R²: {mean_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(random_state=42, max_iter=500)\n",
    "mlp_params = {'hidden_layer_sizes': [(50,), (100,), (50, 50)], \n",
    "              'alpha': [0.0001, 0.001, 0.01]}\n",
    "mlp_cv = GridSearchCV(mlp, mlp_params, cv=5, scoring='r2')\n",
    "mlp_cv.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_cv.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Best Parameters for MLPRegressor:\", mlp_cv.best_params_)\n",
    "\n",
    "print(\"\\nResults for each parameter combination:\")\n",
    "for params, mean_r2 in zip(mlp_cv.cv_results_['params'], mlp_cv.cv_results_['mean_test_score']):\n",
    "    print(f\"Hidden Layer Sizes: {params['hidden_layer_sizes']}, Alpha: {params['alpha']} | Mean R²: {mean_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "svr_params = {'C': [0.1, 1, 10], \n",
    "              'gamma': ['scale', 'auto'], \n",
    "              'kernel': ['rbf', 'linear']}\n",
    "svr_cv = GridSearchCV(svr, svr_params, cv=5, scoring='r2')\n",
    "svr_cv.fit(X_train, y_train)\n",
    "y_pred_svr = svr_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters for SVR:\", svr_cv.best_params_)\n",
    "\n",
    "print(\"\\nResults for each parameter combination:\")\n",
    "for params, mean_r2 in zip(svr_cv.cv_results_['params'], svr_cv.cv_results_['mean_test_score']):\n",
    "    print(f\"C: {params['C']}, Gamma: {params['gamma']}, Kernel: {params['kernel']} | Mean R²: {mean_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{name}:\\n\\tMSE: {mse:.4f}\\n\\tRMSE: {rmse:.4f}\\n\\tR2: {r2:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Performance Regression:\")\n",
    "evaluate_model(\"Linear Regression\", y_test, y_pred_linear)\n",
    "evaluate_model(\"Ridge Regression\", y_test, y_pred_ridge)\n",
    "evaluate_model(\"Lasso Regression\", y_test, y_pred_lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Performance Advanced:\")\n",
    "evaluate_model(\"MLP Regressor\", y_test, y_pred_mlp)\n",
    "evaluate_model(\"Support Vector Regression\", y_test, y_pred_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scale = 5.0  \n",
    "noise = np.random.normal(0, noise_scale, size=y_train.shape)\n",
    "y_train_noisy = y_train + noise\n",
    "\n",
    "linear.fit(X_train, y_train_noisy)\n",
    "y_pred_linear_noisy = linear.predict(X_test)\n",
    "\n",
    "ridge_cv.fit(X_train, y_train_noisy)\n",
    "y_pred_ridge_noisy = ridge_cv.predict(X_test)\n",
    "\n",
    "lasso_cv.fit(X_train, y_train_noisy)\n",
    "y_pred_lasso_noisy = lasso_cv.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_cv.fit(X_train, y_train_noisy)\n",
    "y_pred_mlp_noisy = mlp_cv.predict(X_test)\n",
    "\n",
    "svr_cv.fit(X_train, y_train_noisy)\n",
    "y_pred_svr_noisy = svr_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scales = [0.01, 0.1, 0.5, 1.0]\n",
    "results = []\n",
    "\n",
    "for level in noise_scales:\n",
    "    noise = np.random.normal(0, level, size=y_train.shape)\n",
    "    y_train_noisy = y_train + noise\n",
    "\n",
    "    linear.fit(X_train, y_train_noisy)\n",
    "    y_pred_linear_noisy = linear.predict(X_test)\n",
    "\n",
    "    ridge_cv.fit(X_train, y_train_noisy)\n",
    "    y_pred_ridge_noisy = ridge_cv.predict(X_test)\n",
    "\n",
    "    lasso_cv.fit(X_train, y_train_noisy)\n",
    "    y_pred_lasso_noisy = lasso_cv.predict(X_test)\n",
    "    \n",
    "    print(f\"Noise Level: {level}\")\n",
    "    evaluate_model(\"Linear Regression\", y_test, y_pred_linear_noisy)\n",
    "    evaluate_model(\"Ridge Regression\", y_test, y_pred_ridge_noisy)\n",
    "    evaluate_model(\"Lasso Regression\", y_test, y_pred_lasso_noisy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Advanced Model Performance with Noise:\")\n",
    "evaluate_model(\"MLP Regressor (Noisy)\", y_test, y_pred_mlp_noisy)\n",
    "evaluate_model(\"Support Vector Regression (Noisy)\", y_test, y_pred_svr_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Plot results regression\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(y_test.values[:100], label=\"True Values\", marker='o')\n",
    "plt.plot(y_pred_linear[:100], label=\"Linear\", marker='*')\n",
    "plt.plot(y_pred_ridge[:100], label=\"Ridge\", marker='x')\n",
    "plt.plot(y_pred_lasso[:100], label=\"Lasso\", marker='v')\n",
    "plt.title(\"Model Predictions vs True Values (First 100) for regression\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Global Active Power\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Plot results\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(y_test.values[:100], label=\"True Values\", marker='o')\n",
    "plt.plot(y_pred_mlp[:100], label=\"MLP\", marker='s')\n",
    "plt.plot(y_pred_svr[:100], label=\"SVR\", marker='d')\n",
    "plt.title(\"Model Predictions vs True Values (First 100) for advanced models\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Global Active Power\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analiza_danych",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
